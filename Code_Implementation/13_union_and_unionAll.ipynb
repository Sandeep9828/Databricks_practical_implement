{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aec7129-e54b-4fbb-aa4d-8ebaf0772dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row,SparkSession\n",
    "\n",
    "\n",
    "df1 = spark.createDataFrame([\n",
    "    Row(emp_id=100),\n",
    "    Row(emp_id=200),\n",
    "    Row(emp_id=300),\n",
    "])\n",
    "\n",
    "\n",
    "df2 = spark.createDataFrame([\n",
    "    Row(emp_id=300),\n",
    "    Row(emp_id=400),\n",
    "    Row(emp_id=500),\n",
    "])\n",
    "df1.show()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233680c8-4c34-471f-b0e1-0264ed3bcc18",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Union All"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df1.union(df2)\n",
    "\n",
    "df3.display()\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "In  Union all Duplicate Rows are also included as you can see in output\n",
    "this above syntax is used to perform union All operation.\n",
    "if we want to remove duplicate rows from the result set then we can use .distinct()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "032370d0-9d7d-4b2e-b4e4-756645fbf9e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "UNION (remove duplicates)"
    }
   },
   "outputs": [],
   "source": [
    "df_union = df1.union(df2).distinct()\n",
    "\n",
    "df_union.display()\n",
    "\n",
    "\n",
    "'''\n",
    "here in this result you can see there is no duplicate records are there only unique records are present.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe2e502b-2a1f-422f-913e-3ef124daaa1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "13_union_and_unionAll",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
